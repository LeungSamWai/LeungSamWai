---
layout: home
---

<div class="row justify-content-md-center" style="margin-bottom: 20px;">
<div class="col-md-4 col-sm-4">
<div class="text-center">
<img src="/img/photo.png" class="rounded-circle img-fluid my-profile-picture" alt="my picture">
<p class="my-name">Senwei</p>
<p class="my-position">PhD Student</p>
<p class="my-cv" markdown="1">[CV](/img/cv.pdf) (update on 02/01/2022)</p>
</div>
</div>

<div class="col-md-7 col-sm-7" markdown="1">
Hello friends! Welcome to my page! I am *Senwei Liang*. I joined Lawrence Berkeley National Laboratory working as postdoc in Aug 2022 under supervision by Prof. Chao Yang and Prof. Lin Lin. Before that, I obtained PhD from Purdue University supervised by Prof. [*Haizhao Yang*](https://haizhaoyang.github.io/), and got my MSc degree in National University of 
Singapore and BSc degree in Sun Yat-sen University. 

**Research Interest:** Scientific machine learning and AI with Science.

[Google scholar](https://scholar.google.com/citations?user=NLNoSBsAAAAJ&hl=zh-CN); 
[Semantic scholar](https://www.semanticscholar.org/author/Senwei-Liang/116746634);
[Github](https://leungsamwai.github.io/). 
</div>
</div>

<hr>
<h3 class="text-center">News</h3>
- 

<hr>

<h3 class="text-center">Awards</h3>
- CVPR Outstanding Reviewer (USD 100) [Link](https://cvpr2022.thecvf.com/outstanding-reviewers).
- Ross-Lynn fellowship, Purdue University, 2021-2022.
- Top Graduate Tutors for AY2019/20 (SGD 100), Department of Mathematics, NUS.
- 2020 Thirty-fourth AAAI Conference Scholarship (USD 100).
<hr>

<h3 class="text-center">Work Experience</h3>

- Wallace Givens Associate at Argonne National Laboratory mentored by [Dr. Hong Zhang](https://caidao22.github.io/), from May 2021 to Jul 2021.
- Research Assistant at Computational Medical Imaging Laboratory mentored by [Prof. Yao Lu](https://ieeexplore.ieee.org/author/37086386972), from Jun 2016 to Jan 2017.

<hr>

<h3 class="text-center">Academic Service</h3>

- Conference reviewer: AAAI, CVPR, ECCV, ICANN
- Journal reviewer: Journal of Scientific Computing
- Organizer: AMS Sectional meeting at Purdue, the SIAM Texas-Louisiana Section
- Assistant: IMA Workshop at Purdue

<hr>
<h3 class="text-center">Publications or Manuscripts</h3>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/density.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2023) Stationary Density Estimation of Itô Diffusions Using Deep Learning</p>
<p class="my-pub-summary">We propose a deep learning scheme to estimate the density from a discrete-time series that approximate the solutions of the stochastic
differential equations. We establish the convergence of the proposed scheme. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
Y. Gu, J. Harlim, **S. Liang**, H. Yang, SIAM Journal on Numerical Analysis (Corresp. author) [[PDF](https://epubs.siam.org/doi/abs/10.1137/21M1445363)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/ensemble.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2022) Accelerating numerical solvers for large-scale simulation of dynamical system via NeurVec </p>
<p class="my-pub-summary">  We propose a data-driven corrector method that allows using large step sizes while compensating for the integration error for high accuracy. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
Z. Huang, **S. Liang**, H. Zhang, H. Yang, L. Lin, submitted (Joint first)  [[PDF](https://arxiv.org/pdf/2208.03680.pdf), [Code](https://github.com/dedekinds/NeurVec)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/fex.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2022) Finite Expression Method for Solving High-Dimensional Partial Differential Equations </p>
<p class="my-pub-summary"> We introduce a new methodology that seeks an approximate PDE solution in the space of functions with finitely many analytic expressions and, hence, this methodology is named the finite expression method (FEX). </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, H. Yang, submitted (2022) [[PDF](https://arxiv.org/abs/2206.10121), [Code](https://github.com/LeungSamWai/Finite-expression-method)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/cover.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2022) Quantifying spatial homogeneity of urban road networks via graph neural networks </p>
<p class="my-pub-summary">We borrow the power of graph neural networks to model the road network system and use its predictability to quantify the spatial homogeneity. The proposed measurement is shown to be a non-linear integration of multiple geometric properties. We demonstrate its connection with the road irregularity and the socioeconomic status indicators. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
J. Xue, N. Jiang, **S. Liang**, Q. Pang, T. Yabe, S. Ukkusuri, J. Ma, Nature Machine Intelligence, 4, 246–257 (2022) [[PDF](https://www.nature.com/articles/s42256-022-00462-y)], [[Code](https://github.com/jiang719/road-network-predictability)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/sann.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2021) Stiffness-aware neural network for learning Hamiltonian systems</p>
<p class="my-pub-summary">We propose stiffness-aware neural network, a new method for learning stiff Hamiltonian dynamical systems from data.
SANN identifies and splits the training data into stiff and nonstiff portions based on a stiffness-aware index, a metric to quantify the stiffness of the dynamical system. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, Z. Huang, H. Zhang, ICLR 2022 [[PDF](https://openreview.net/forum?id=uVXEKeqJbNa)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/face.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2021) Solving PDEs on Unknown Manifolds with Machine Learning </p>
<p class="my-pub-summary">We propose a mesh-free computational framework and machine learning theory for solving elliptic PDEs on unknown manifolds, identified with point clouds, based on diffusion maps (DM) and deep learning. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, S. Jiang, J. Harlim, H. Yang, Submitted, [[PDF](https://arxiv.org/pdf/2106.06682.pdf)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/bach.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2021) Reproducing Activation Function for Deep Learning </p>
<p class="my-pub-summary">We propose reproducing activation functions which employs several basic functions and their learnable linear combination to construct neuron-wise data-driven activation functions for each neuron.  </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, L. Lyu, C. Wang, H. Yang, Submitted, (Joint first author) [[PDF](https://arxiv.org/pdf/2101.04844.pdf)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/ean.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2021) Efficient Attention Network: Accelerate Attention by Searching Where to Plug</p>
<p class="my-pub-summary"> To improve the efficiency for the existing attention modules, we leverage the sharing mechanism to share the attention module within the backbone and search where to connect the shared attention module via reinforcement learning. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
Z. Huang, **S. Liang**, M. Liang, W. He, H. Yang, Submitted (Joint first author) [[PDF](https://arxiv.org/abs/2011.14058), [Code](https://github.com/gbup-group/EAN-efficient-attention-network)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/blend.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2021) Blending Pruning Criteria for Convolutional Neural Networks</p>
<p class="my-pub-summary">  We propose a novel framework to integrate the existing filter pruning criteria by exploring the criteria diversity. The proposed framework contains two stages: Criteria Clustering and Filters Importance Calibration. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
W. He, Z. Huang, M. Liang, **S. Liang**, H. Yang, ICANN 2021 [[PDF](https://link.springer.com/chapter/10.1007/978-3-030-86380-7_1)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/ks.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2019) Machine learning for prediction with missing dynamics</p>
<p class="my-pub-summary">We propose a framework that reformulates the prediction problem as a supervised learning problem to approximate a map that takes the memories of the resolved and identifiable unresolved variables to the missing components in the resolved dynamics.</p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
J. Harlim, S. Jiang, **S. Liang**, H. Yang, J. Comput. Phys., (Alphabetical order) [[PDF](https://www.sciencedirect.com/science/article/pii/S0021999120306963)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/iebn.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2019) Instance Enhancement Batch Normalization: An Adaptive Regulator of Batch Noise</p>
<p class="my-pub-summary">We point out that self-attention mechanism can help to regulate the noise by enhancing instance-specific information and propose a normalization that recalibrates the information of each channel by a simple linear transformation.</p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, Z. Huang, M. Liang, H. Yang, AAAI-2020 [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/5917), [Code](https://github.com/gbup-group/IEBN)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/dia.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2019) DIANet: Dense-and-Implicit Attention Network</p>
<p class="my-pub-summary">We propose a framework that shares an attention module throughout different network layers to encourage the integration of layer-wise information. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
Z. Huang, **S. Liang**, M. Liang, H. Yang, AAAI-2020, (Joint first) [[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/5842), [Code](https://github.com/gbup-group/DIANet)].
</p>
</div>
</div>

<hr>

<div class="row my-pub-main">
<div class="col-12 col-sm-4">
<div class="text-center">
<img src="/img/dropact.png" class="rounded img-fluid my-profile-picture">
</div>
</div>
<div class="col-12 col-sm-8 my-pub-r">
<p class="my-pub-heading">(2018) Drop-activation: Implicit parameter reduction and harmonic regularization</p>
<p class="my-pub-summary">We propose a regularization method that
drops nonlinear activation functions by setting them to be identity functions randomly during training time. </p>
<div style="margin-bottom: 10px;"></div>
<p markdown="1">
**S. Liang**, Y. Khoo, H. Yang, Communications on Applied Mathematics and Computation [[PDF](https://link.springer.com/article/10.1007/s42967-020-00085-3), [Code](https://github.com/LeungSamWai/Drop-Activation)].
</p>
</div>
</div>

<hr>

This page has been accessed at least
<a href="http://stuff.mit.edu/doc/counter-howto.html"><img 
src="http://stuff.mit.edu/cgi/counter/leungsamwai" alt="several"></a>
times since 10/10/2021, and on average <a href="http://stuff.mit.edu/doc/counter-howto.html"><img 
src="http://stuff.mit.edu/cgi/perday/leungsamwai" alt="several"></a> per day. 
